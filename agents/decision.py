import json
from typing import Dict, Any
from utils.llm_client import LLMClient

class DecisionAgent:
    def __init__(self, llm_client: LLMClient):
        self.llm = llm_client

    def decide(self, match_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """
        Makes a final hiring recommendation based on the detailed match analysis.
        """
        
        system_prompt = """
        You are the Final Decision Maker. Review the match analysis and output a structured hiring decision.
        
        Output JSON:
        {
          "match_score": float (copy from input),
          "recommendation": "Proceed to interview | Reject | Needs manual review",
          "requires_human": boolean,
          "confidence": float (0.0 - 1.0),
          "reasoning_summary": "A clear, human-readable paragraph explaining WHY."
        }
        
        Logic:
        - If match_score > 0.75 and no critical gaps -> Proceed
        - If match_score < 0.4 -> Reject
        - If match_score is borderline or uncertainty_flag is true -> Needs manual review
        - If missing_critical_skills is not empty -> Generally Reject or Manual Review if strong elsewhere.
        """

        user_prompt = f"""
        Match Analysis:
        {json.dumps(match_analysis, indent=2)}
        """

        # We don't strictly *need* an LLM here if the logic is pure if/else, 
        # but the request asks for "reasoning_summary" which is best generated by LLM 
        # based on the structured data + nuances.
        return self.llm.query(system_prompt, user_prompt, expect_json=True)
